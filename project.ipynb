{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dr-Future/CSC413-project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CURRENT PREGRESS AND NOTES:\n",
        "\n",
        "It takes 10 sec to run 1 epoch on colab\n",
        "\n",
        "After 100 epochs of training the model performs much better. Problems is, in the area where it's supposed to be completely black or white, the model outputs opposite color pixel.\n",
        "\n",
        "Maybe try Adam rather than SGD\n",
        "\n",
        "I forgot to save the work after training for 100 epochs"
      ],
      "metadata": {
        "id": "NSa60u7DEBNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl --remote-name -sSfL https://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\n",
        "!tar xzf BSR_bsds500.tgz"
      ],
      "metadata": {
        "id": "kjG9_1zyJ5F_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages"
      ],
      "metadata": {
        "id": "qgFvI6b8HdJz",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1YfLyw9jHVIa",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import argparse\n",
        "import math\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import scipy.misc\n",
        "import torch\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, ToPILImage\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility functions"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "HWWb-80qDm_L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "path = \"BSR/BSDS500/data/images\""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TF2f6xq1Dm_M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "# Move all samples in test folder to train folder\n",
        "# So that we have 400 training examples\n",
        "\n",
        "%mv BSR/BSDS500/data/images/test/*.jpg BSR/BSDS500/data/images/train"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TAeYIIWHDm_N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": [
        "class BSDS500Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path: str, mode: str, scale: int, resize: int):\n",
        "        self.path = path\n",
        "        self.mode = mode # train / test / val\n",
        "        self.scale = scale\n",
        "        self.resize = resize\n",
        "        self.file_names = [os.path.join(self.path, self.mode, file_name) for file_name in os.listdir(os.path.join(self.path, self.mode)) if file_name.endswith(\".jpg\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        file_name = self.file_names[index]\n",
        "        image = Image.open(file_name)\n",
        "\n",
        "        # Convert to YUV and split the channels\n",
        "        image.convert(\"YCbCr\")\n",
        "        y, u, v = image.split()\n",
        "\n",
        "        # Calculate size\n",
        "        low_res_size = self.resize // self.scale\n",
        "        high_res_size = low_res_size * self.scale\n",
        "\n",
        "        # low_res_size = [image.size[1] // self.scale, image.size[0] // self.scale]\n",
        "        # high_res_size = [low_res_size[0] * self.scale, low_res_size[1] * self.scale]\n",
        "\n",
        "        # Rescale images to square\n",
        "        low_composed = Compose([\n",
        "            Resize([low_res_size, low_res_size], interpolation=InterpolationMode.BICUBIC),\n",
        "            ToTensor()\n",
        "        ])\n",
        "\n",
        "        high_composed = Compose([\n",
        "            Resize([high_res_size, high_res_size], interpolation=InterpolationMode.BICUBIC),\n",
        "            ToTensor()\n",
        "        ])\n",
        "\n",
        "        sample = { \"y_low\": low_composed(y).cuda(), \"u_low\": low_composed(u).cuda(), \"v_low\": low_composed(v).cuda(),\n",
        "               \"y_high\": high_composed(y).cuda(), \"u_high\": high_composed(u).cuda(), \"v_high\": high_composed(v).cuda(),\n",
        "               \"high\": high_composed(image).cuda() }\n",
        "        return sample\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "syvEe3KfDm_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESPCN model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "a0Pf5rbtDm_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class ESPCN_model(nn.Module):\n",
        "    def __init__(self, layer1_channel, layer2_channel, upscale_factor):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, layer1_channel, kernel_size=5, stride=1, padding=2),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(layer1_channel, layer2_channel, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(layer2_channel, upscale_factor ** 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.PixelShuffle(upscale_factor) # This function is literally build for ESPCN\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        return out"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vQzDVgEjDm_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for validation"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G9anRABkDm_Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def run_validation_step(\n",
        "    cnn,\n",
        "    criterion,\n",
        "    val_set,\n",
        "):\n",
        "    losses = []\n",
        "    for i_batch, sample_batched in enumerate(val_set):\n",
        "          input = sample_batched[\"y_low\"]\n",
        "          out = cnn(input)\n",
        "\n",
        "          loss = criterion(out, sample_batched[\"y_high\"])\n",
        "          losses.append(loss.data.item())\n",
        "\n",
        "    # if plotpath:  # only plot if a path is provided\n",
        "    #     plot(\n",
        "    #         xs,\n",
        "    #         ys,\n",
        "    #         predicted.cpu().numpy(),\n",
        "    #         colours,\n",
        "    #         plotpath,\n",
        "    #         visualize=visualize,\n",
        "    #         compare_bilinear=downsize_input,\n",
        "    #     )\n",
        "\n",
        "    val_loss = np.mean(losses)\n",
        "    return val_loss"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Zv739LcHDm_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for training (adapted from PA2)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qtDyptH0Dm_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from matplotlib import transforms\n",
        "from torch._C import wait\n",
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "def train(args, cnn=None):\n",
        "    # Set the maximum number of threads to prevent crash in Teaching Labs\n",
        "    # torch.set_num_threads(5)\n",
        "\n",
        "    # Numpy random seed\n",
        "    npr.seed(args.seed)\n",
        "\n",
        "    # Save directory\n",
        "    save_dir = \"outputs/\" + args.experiment_name\n",
        "\n",
        "    # INPUT CHANNEL\n",
        "    num_in_channels = 1\n",
        "\n",
        "    # LOAD THE MODEL\n",
        "    if cnn is None:\n",
        "        cnn = ESPCN_model(64, 32, 3)\n",
        "\n",
        "    # LOSS FUNCTION\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4, nesterov=False)\n",
        "\n",
        "    # DATA\n",
        "    print(\"Loading data...\")\n",
        "    trainset = torch.utils.data.DataLoader(BSDS500Dataset(path, \"train\", 3, args.resize), batch_size = args.batch_size)\n",
        "    testset = torch.utils.data.DataLoader(BSDS500Dataset(path, \"val\", 3, args.resize), batch_size = args.batch_size)\n",
        "\n",
        "    # for item in trainset:\n",
        "    #   print(item)\n",
        "\n",
        "    # y.save(\"temp.jpg\", \"JPEG\")\n",
        "\n",
        "    # print(\"Transforming data...\")\n",
        "    # train_rgb, train_grey = process(x_train, y_train, downsize_input=args.downsize_input)\n",
        "    # train_rgb_cat = get_rgb_cat(train_rgb, colours)\n",
        "    # test_rgb, test_grey = process(x_test, y_test, downsize_input=args.downsize_input)\n",
        "    # test_rgb_cat = get_rgb_cat(test_rgb, colours)\n",
        "\n",
        "    # Create the outputs folder if not created already\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    print(\"Beginning training ...\")\n",
        "    if args.gpu:\n",
        "        cnn.cuda()\n",
        "    start = time.time()\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    valid_accs = []\n",
        "    for epoch in range(args.epochs):\n",
        "        # Train the Model\n",
        "        cnn.train()  # Change model to 'train' mode\n",
        "        losses = []\n",
        "\n",
        "        for i_batch, sample_batched in enumerate(trainset):\n",
        "          input = sample_batched[\"y_low\"]\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          out = cnn(input)\n",
        "\n",
        "          # print(out.size())\n",
        "          # print(sample_batched[\"y_high\"].size())\n",
        "\n",
        "          loss = criterion(out, sample_batched[\"y_high\"])\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          losses.append(loss.data.item())\n",
        "\n",
        "        # plot training images\n",
        "        # if args.plot:\n",
        "        #     _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
        "        #     plot(\n",
        "        #         xs,\n",
        "        #         ys,\n",
        "        #         predicted.cpu().numpy(),\n",
        "        #         colours,\n",
        "        #         save_dir + \"/train_%d.png\" % epoch,\n",
        "        #         args.visualize,\n",
        "        #         args.downsize_input,\n",
        "        #     )\n",
        "\n",
        "        # plot training images\n",
        "        avg_loss = np.mean(losses)\n",
        "        train_losses.append(avg_loss)\n",
        "        time_elapsed = time.time() - start\n",
        "        print(\n",
        "            \"Epoch [%d/%d], Loss: %.4f, Time (s): %d\"\n",
        "            % (epoch + 1, args.epochs, avg_loss, time_elapsed)\n",
        "        )\n",
        "\n",
        "        # Evaluate the model\n",
        "        # cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
        "\n",
        "        # val_loss = run_validation_step(\n",
        "        #     cnn,\n",
        "        #     criterion,\n",
        "        #     testset,\n",
        "        #     args.batch_size,\n",
        "        #     # save_dir + \"/test_%d.png\" % epoch,\n",
        "        # )\n",
        "\n",
        "        # time_elapsed = time.time() - start\n",
        "        # valid_losses.append(val_loss)\n",
        "        # print(\n",
        "        #     \"Epoch [%d/%d], Val Loss: %.4f, Time(s): %.2f\"\n",
        "        #     % (epoch + 1, args.epochs, val_loss, time_elapsed)\n",
        "        # )\n",
        "\n",
        "    # Plot training curve\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, \"ro-\", label=\"Train\")\n",
        "    plt.plot(valid_losses, \"go-\", label=\"Validation\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.savefig(save_dir + \"/training_curve.png\")\n",
        "\n",
        "    if args.checkpoint:\n",
        "        print(\"Saving model...\")\n",
        "        torch.save(cnn.state_dict(), args.checkpoint)\n",
        "\n",
        "    return cnn"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dPEllswFDm_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Oru2s9VqDm_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "    \"gpu\": True,\n",
        "    \"valid\": False,\n",
        "    \"checkpoint\": \"\",\n",
        "    \"model\": \"ESPCN\",\n",
        "    \"resize\": 481,  # Images will be transformed to [resize, resize] square image\n",
        "    \"kernel\": 3,\n",
        "    \"num_filters\": 32,\n",
        "    'learn_rate':0.001,\n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 100,\n",
        "    \"seed\": 42,\n",
        "    \"plot\": True,\n",
        "    \"experiment_name\": \"ESPCN\",\n",
        "    \"visualize\": False,\n",
        "    \"downsize_input\": False,\n",
        "}\n",
        "args.update(args_dict)\n",
        "cnn = train(args)\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pny-9IhwDm_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BRI8IDUmDm_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "val_set = BSDS500Dataset(path, \"val\", 3, 481)\n",
        "\n",
        "index = 0\n",
        "cnn.eval()\n",
        "for item in val_set:\n",
        "\n",
        "  if index == 50:\n",
        "    img_arr = item[\"y_low\"]\n",
        "    img = ToPILImage()(img_arr)\n",
        "    img.save(\"in.jpg\", \"JPEG\")\n",
        "\n",
        "    out = cnn(img_arr.unsqueeze(0))\n",
        "    out_img = ToPILImage()(out.squeeze(0))\n",
        "    out_img.save(\"out.jpg\", \"JPEG\")\n",
        "\n",
        "  index += 1\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "s3F_G5alDm_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result:\n",
        "\n",
        "Under setting batch_size = 64, epochs = 100:\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KW7fuFddDm_T"
      }
    }
  ]
}