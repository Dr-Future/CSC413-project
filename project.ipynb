{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "project.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import packages"
   ],
   "metadata": {
    "id": "qgFvI6b8HdJz",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1YfLyw9jHVIa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\FUTURE~1\\AppData\\Local\\Temp/ipykernel_12500/415473840.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnpr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmisc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunctional\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "from PIL import Image\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy.misc\n",
    "import torch\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Download dataset\n",
    "origin = \"https://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\"\n",
    "f = \"BSR_bsds500.tar.gz\"\n",
    "\n",
    "try:\n",
    "    try:\n",
    "        urlretrieve(origin, f)\n",
    "    except URLError as e:\n",
    "        raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
    "    except HTTPError as e:\n",
    "        raise Exception(error_msg.format(origin, e.code, e.msg))\n",
    "except (Exception, KeyboardInterrupt) as e:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "    raise\n",
    "\n",
    "with tarfile.open(f) as archive:\n",
    "    archive.extractall(\".\")\n",
    "\n",
    "os.remove(f)\n",
    "\n",
    "path = \"BSR/BSDS500/data/images\""
   ],
   "metadata": {
    "id": "t0qpZKA0au-o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class BSDS500Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: str, mode: str, scale: int):\n",
    "        self.path = path\n",
    "        self.mode = mode # train / test / val\n",
    "        self.scale = scale\n",
    "        self.file_names = [os.path.join(self.path, self.mode, file_name) for file_name in os.listdir(os.path.join(self.path, self.mode)) if file_name.endswith(\".jpg\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        file_name = self.file_names[index]\n",
    "        image = Image.open(file_name)\n",
    "\n",
    "        # Convert yo YUV and split the channels\n",
    "        image.convert(\"YCbCr\")\n",
    "        y, u, v = image.split()\n",
    "\n",
    "        low_res_size = [image.size[1] // self.scale, image.size[0] // self.scale]\n",
    "        high_res_size = [low_res_size[0] * self.scale, low_res_size[1] * self.scale]\n",
    "\n",
    "        low_composed = Compose([\n",
    "            Resize(low_res_size, interpolation=InterpolationMode.BICUBIC),\n",
    "            ToTensor()\n",
    "        ])\n",
    "\n",
    "        high_composed = Compose([\n",
    "            Resize(high_res_size, interpolation=InterpolationMode.BICUBIC),\n",
    "            ToTensor()\n",
    "        ])\n",
    "\n",
    "        sample = { \"y_low\": low_composed(y).cuda(), \"u_low\": low_composed(u).cuda(), \"v_low\": low_composed(v).cuda(),\n",
    "               \"y_high\": high_composed(y).cuda(), \"u_high\": high_composed(u).cuda(), \"v_high\": high_composed(v).cuda(),\n",
    "               \"high\": high_composed(image).cuda() }\n",
    "        return sample\n",
    "\n",
    "trainset = BSDS500Dataset(path, \"train\", 3)\n",
    "testset = BSDS500Dataset(path, \"test\", 3)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(trainset)):\n",
    "    sample = trainset[i]\n",
    "    print(i, sample[\"y_low\"].size(), sample[\"high\"].size())\n",
    "    if i == 1:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Twct87mDdlsY",
    "outputId": "aaee7d6d-5ec9-4e4b-c1b8-42227de0fc52",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 torch.Size([3, 160, 107]) torch.Size([3, 321, 481])\n",
      "1 torch.Size([3, 107, 160]) torch.Size([3, 481, 321])\n",
      "2 torch.Size([3, 160, 107]) torch.Size([3, 321, 481])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The actual ESPCN model"
   ],
   "metadata": {
    "id": "KNj2Rq4iIcan",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ESPCN_model(nn.Module):\n",
    "    def __init__(self, layer1_channel, layer2_channel, upscale_factor):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, layer1_channel, kernel_size=5, stride=1, padding=2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(layer1_channel, layer2_channel, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(layer2_channel, upscale_factor ** 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.PixelShuffle(upscale_factor) # This function is literally build for ESPCN\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        return out"
   ],
   "metadata": {
    "id": "b5--A1VEIc2J",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code for training (adapted from PA2)\n",
    "The training part works, at least no error, I'll check the output later\n",
    "\n",
    "Currently I use SGD (batch size 1) just for testing"
   ],
   "metadata": {
    "id": "zOJ1G8nmHgWp",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib import transforms\n",
    "from torch._C import wait\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "def train(args, cnn=None):\n",
    "    # Set the maximum number of threads to prevent crash in Teaching Labs\n",
    "    # torch.set_num_threads(5)\n",
    "\n",
    "    # Numpy random seed\n",
    "    npr.seed(args.seed)\n",
    "\n",
    "    # Save directory\n",
    "    save_dir = \"outputs/\" + args.experiment_name\n",
    "\n",
    "    # INPUT CHANNEL\n",
    "    num_in_channels = 1\n",
    "\n",
    "    # LOAD THE MODEL\n",
    "    if cnn is None:\n",
    "        cnn = ESPCN_model(64, 32, 3)\n",
    "\n",
    "    # LOSS FUNCTION\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4, nesterov=False)\n",
    "\n",
    "    # DATA\n",
    "    print(\"Loading data...\")\n",
    "    # (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
    "\n",
    "    # y.save(\"temp.jpg\", \"JPEG\")\n",
    "\n",
    "    # print(\"Transforming data...\")\n",
    "    # train_rgb, train_grey = process(x_train, y_train, downsize_input=args.downsize_input)\n",
    "    # train_rgb_cat = get_rgb_cat(train_rgb, colours)\n",
    "    # test_rgb, test_grey = process(x_test, y_test, downsize_input=args.downsize_input)\n",
    "    # test_rgb_cat = get_rgb_cat(test_rgb, colours)\n",
    "\n",
    "    # Create the outputs folder if not created already\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    print(\"Beginning training ...\")\n",
    "    if args.gpu:\n",
    "        cnn.cuda()\n",
    "    start = time.time()\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    for epoch in range(args.epochs):\n",
    "        # Train the Model\n",
    "        cnn.train()  # Change model to 'train' mode\n",
    "        losses = []\n",
    "\n",
    "\n",
    "        for i in range(len(trainset)):\n",
    "          sample = trainset[i]\n",
    "          input = sample[\"y_low\"].unsqueeze(0)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          output = cnn(input)\n",
    "          # print(input.size())\n",
    "          # print(output.size())\n",
    "\n",
    "          loss = criterion(output, sample[\"y_high\"].unsqueeze(0))\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          losses.append(loss.data.item())\n",
    "\n",
    "        # plot training images\n",
    "        # if args.plot:\n",
    "        #     _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
    "        #     plot(\n",
    "        #         xs,\n",
    "        #         ys,\n",
    "        #         predicted.cpu().numpy(),\n",
    "        #         colours,\n",
    "        #         save_dir + \"/train_%d.png\" % epoch,\n",
    "        #         args.visualize,\n",
    "        #         args.downsize_input,\n",
    "        #     )\n",
    "\n",
    "        # plot training images\n",
    "        avg_loss = np.mean(losses)\n",
    "        train_losses.append(avg_loss)\n",
    "        time_elapsed = time.time() - start\n",
    "        print(\n",
    "            \"Epoch [%d/%d], Loss: %.4f, Time (s): %d\"\n",
    "            % (epoch + 1, args.epochs, avg_loss, time_elapsed)\n",
    "        )\n",
    "\n",
    "        # Evaluate the model\n",
    "        # cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        # val_loss, val_acc = run_validation_step(\n",
    "        #     cnn,\n",
    "        #     criterion,\n",
    "        #     test_grey,\n",
    "        #     test_rgb_cat,\n",
    "        #     args.batch_size,\n",
    "        #     colours,\n",
    "        #     save_dir + \"/test_%d.png\" % epoch,\n",
    "        #     args.visualize,\n",
    "        #     args.downsize_input,\n",
    "        # )\n",
    "\n",
    "        # time_elapsed = time.time() - start\n",
    "        # valid_losses.append(val_loss)\n",
    "        # valid_accs.append(val_acc)\n",
    "        # print(\n",
    "        #     \"Epoch [%d/%d], Val Loss: %.4f, Val Acc: %.1f%%, Time(s): %.2f\"\n",
    "        #     % (epoch + 1, args.epochs, val_loss, val_acc, time_elapsed)\n",
    "        # )\n",
    "\n",
    "    # Plot training curve\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, \"ro-\", label=\"Train\")\n",
    "    plt.plot(valid_losses, \"go-\", label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.savefig(save_dir + \"/training_curve.png\")\n",
    "\n",
    "    if args.checkpoint:\n",
    "        print(\"Saving model...\")\n",
    "        torch.save(cnn.state_dict(), args.checkpoint)\n",
    "\n",
    "    return cnn"
   ],
   "metadata": {
    "cellView": "code",
    "id": "3Ff3lUQzHhJQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the model"
   ],
   "metadata": {
    "id": "2A-HLZ-2Wv29",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "args = AttrDict()\n",
    "args_dict = {\n",
    "    \"gpu\": True,\n",
    "    \"valid\": False,\n",
    "    \"checkpoint\": \"\",\n",
    "    \"colours\": \"./data/colours/colour_kmeans24_cat7.npy\",\n",
    "    \"model\": \"UNet\",\n",
    "    \"kernel\": 3,\n",
    "    \"num_filters\": 32,\n",
    "    'learn_rate':0.001,\n",
    "    \"batch_size\": 100,\n",
    "    \"epochs\": 10,\n",
    "    \"seed\": 42,\n",
    "    \"plot\": True,\n",
    "    \"experiment_name\": \"colourization_cnn\",\n",
    "    \"visualize\": False,\n",
    "    \"downsize_input\": False,\n",
    "}\n",
    "args.update(args_dict)\n",
    "cnn = train(args)\n"
   ],
   "metadata": {
    "id": "hKUcO-YqWxvW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}