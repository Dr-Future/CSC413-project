{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dr-Future/CSC413-project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CURRENT PREGRESS AND NOTES:\n",
        "\n",
        "After 100 epochs of training the model performs much better. Problems is, in the area where it's supposed to be completely black or white, the model outputs opposite color pixel.\n",
        "\n",
        "Maybe try Adam rather than SGD\n",
        "\n",
        "I forgot to save the work after training for 100 epochs"
      ],
      "metadata": {
        "id": "NSa60u7DEBNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Download"
      ],
      "metadata": {
        "id": "noRLrY17zw2U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YfLyw9jHVIa",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import torch\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, ToPILImage\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 67M\n",
        "!curl --remote-name -L https://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\n",
        "!tar xzf BSR_bsds500.tgz\n",
        "!rm BSR_bsds500.tgz\n",
        "!mv BSR/BSDS500/data/images/* BSR/BSDS500\n",
        "!rm -r BSR/bench\n",
        "!rm -r BSR/documentation\n",
        "!rm -r BSR/BSDS500/data\n",
        "\n",
        "# Move all samples in test folder to train folder\n",
        "# So that we have 400 training examples\n",
        "# %mv BSR/BSDS500/data/images/test/*.jpg BSR/BSDS500/data/images/train\n",
        "\n",
        "# 428M\n",
        "!curl --remote-name -L https://image-net.org/data/ILSVRC/2017/ILSVRC2017_DET_test_new.tar.gz\n",
        "!tar xzf ILSVRC2017_DET_test_new.tar.gz\n",
        "!rm ILSVRC2017_DET_test_new.tar.gz\n",
        "!mv ILSVRC/Data/DET/test/*.JPEG ILSVRC\n",
        "!rm -r ILSVRC/Data\n",
        "!rm -r ILSVRC/ImageSets"
      ],
      "metadata": {
        "id": "kjG9_1zyJ5F_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f766a02-1f63-4f06-9bb1-7ace7d9a3f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 67.4M  100 67.4M    0     0  33.5M      0  0:00:02  0:00:02 --:--:-- 40.2M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  427M  100  427M    0     0  13.9M      0  0:00:30  0:00:30 --:--:-- 13.6M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "HWWb-80qDm_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self"
      ],
      "metadata": {
        "id": "vqQUEaUMzYUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class BSDS500Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, split, scale, resize):\n",
        "        self.root = \"BSR/BSDS500\"\n",
        "        self.split = split # train / test / val\n",
        "        self.scale = scale\n",
        "        self.resize = resize\n",
        "        self.low_res_size = self.resize // self.scale\n",
        "        self.high_res_size = self.low_res_size * self.scale\n",
        "        self.file_names = [os.path.join(self.root, self.split, file_name) for file_name in os.listdir(os.path.join(self.root, self.split)) if file_name.endswith(\".jpg\")]\n",
        "\n",
        "        # Rescale images to square\n",
        "        self.low_composed = Compose([\n",
        "            Resize([self.low_res_size, self.low_res_size], interpolation=InterpolationMode.BICUBIC),\n",
        "            ToTensor()\n",
        "        ])\n",
        "\n",
        "        self.high_composed = Compose([\n",
        "            Resize([self.high_res_size, self.high_res_size], interpolation=InterpolationMode.BICUBIC),\n",
        "            ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Convert to YUV and split the channels\n",
        "        image = Image.open(self.file_names[index]).convert(\"YCbCr\")\n",
        "        y, u, v = image.split()\n",
        "\n",
        "        return { \"y_low\": self.low_composed(y).cuda(), \"u_low\": self.low_composed(u).cuda(), \"v_low\": self.low_composed(v).cuda(),\n",
        "               \"y_high\": self.high_composed(y).cuda() }\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "syvEe3KfDm_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ILSVRC2017Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, scale: int, resize: int):\n",
        "        self.root = \"ILSVRC\"\n",
        "        self.scale = scale\n",
        "        self.resize = resize\n",
        "        self.low_res_size = self.resize // self.scale\n",
        "        self.high_res_size = self.low_res_size * self.scale\n",
        "        self.file_names = [os.path.join(self.root, file_name) for file_name in os.listdir(self.root) if file_name.endswith(\".JPEG\")]\n",
        "\n",
        "        # Rescale images to square\n",
        "        self.low_composed = Compose([\n",
        "            Resize([self.low_res_size, self.low_res_size], interpolation=InterpolationMode.BICUBIC),\n",
        "            ToTensor()\n",
        "        ])\n",
        "\n",
        "        self.high_composed = Compose([\n",
        "            Resize([self.high_res_size, self.high_res_size], interpolation=InterpolationMode.BICUBIC),\n",
        "            ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Convert to YUV and split the channels\n",
        "        image = Image.open(self.file_names[index]).convert(\"YCbCr\")\n",
        "        y, u, v = image.split()\n",
        "        return { \"y_low\": self.low_composed(y).cuda(), \"y_high\": self.high_composed(y).cuda() }"
      ],
      "metadata": {
        "id": "16MNn2Ms5SSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate PSNR between two images (tensor)\n",
        "def psnr(img_1, img_2):\n",
        "    mse = torch.mean((img_1 - img_2) ** 2)\n",
        "    if(mse == 0):\n",
        "        return 100\n",
        "    max_pixel = 1\n",
        "    psnr = 20 * math.log10(max_pixel / math.sqrt(mse))\n",
        "    return psnr"
      ],
      "metadata": {
        "id": "pz-10hTqhkS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESPCN"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "a0Pf5rbtDm_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "class ESPCN_model(nn.Module):\n",
        "    def __init__(self, layer1_channel, layer2_channel, upscale_factor):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, layer1_channel, kernel_size=5, stride=1, padding=2),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(layer1_channel, layer2_channel, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(layer2_channel, upscale_factor ** 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.PixelShuffle(upscale_factor) # This function is literally built for ESPCN\n",
        "        )\n",
        "\n",
        "        self.apply(init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        return out"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vQzDVgEjDm_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNet"
      ],
      "metadata": {
        "id": "ODWynRpJP3mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From PA2\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, kernel, num_filters, num_colours, num_in_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        # Useful parameters\n",
        "        stride = 1\n",
        "        padding = kernel // 2\n",
        "        output_padding = 0\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=3, mode='bicubic')\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(num_in_channels, num_filters, kernel, stride, padding),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(num_filters, 2 * num_filters, kernel, stride, padding),\n",
        "            nn.BatchNorm2d(2 * num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(2 * num_filters, num_filters, kernel, stride, padding, output_padding, dilation=1),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(num_filters + num_filters, num_colours, kernel, stride, padding, output_padding, dilation=1),\n",
        "            nn.BatchNorm2d(num_colours),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.output = nn.Conv2d(num_in_channels + num_colours, num_colours, kernel, padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = self.upsample(x)\n",
        "        a = self.block1(u)\n",
        "        b = self.block2(a)\n",
        "        c = self.block3(b)\n",
        "        c1 = torch.cat((a, c), dim=1)\n",
        "        d = self.block4(c1)\n",
        "        d1 = torch.cat((u, d), dim=1)\n",
        "        return self.output(d1)"
      ],
      "metadata": {
        "id": "0fE-nxSEP5Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ttXN0H-QP7aY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for validation"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G9anRABkDm_Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def run_validation_step(\n",
        "    cnn,\n",
        "    criterion,\n",
        "    val_set,\n",
        "):\n",
        "    losses = []\n",
        "    psnrs = []\n",
        "\n",
        "    for i_batch, sample_batched in enumerate(val_set):\n",
        "          input = sample_batched[\"y_low\"]\n",
        "          output = cnn(input)\n",
        "\n",
        "          loss = criterion(output, sample_batched[\"y_high\"])\n",
        "          losses.append(loss.data.item())\n",
        "\n",
        "          psnrs.append(psnr(output.squeeze(), sample_batched[\"y_high\"].squeeze()))\n",
        "\n",
        "    val_loss = np.mean(losses)\n",
        "    val_psnr = np.mean(psnrs)\n",
        "    return val_loss, val_psnr"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Zv739LcHDm_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for training (adapted from PA2)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qtDyptH0Dm_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train(args, cnn=None):\n",
        "    # Numpy random seed\n",
        "    npr.seed(args.seed)\n",
        "\n",
        "    # Save directory\n",
        "    save_dir = \"outputs/\" + args.model\n",
        "\n",
        "    # INPUT CHANNEL\n",
        "    num_in_channels = 1\n",
        "\n",
        "    # LOAD THE MODEL\n",
        "    if cnn is None:\n",
        "        cnn = ESPCN_model(64, 32, 3)\n",
        "\n",
        "    # LOSS FUNCTION\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    if args.optimizor is \"SGD\":\n",
        "      optimizer = torch.optim.SGD(cnn.parameters(), lr=args.learn_rate, momentum=0.9, weight_decay=1e-4, nesterov=False)\n",
        "    elif args.optimizor is \"Adam\":\n",
        "      optimizer = torch.optim.Adam(cnn.parameters(), lr=args.learn_rate)\n",
        "\n",
        "    scheduler = ExponentialLR(optimizer, gamma=0.9, verbose=True)\n",
        "\n",
        "    # DATA\n",
        "    print(\"Loading data...\")\n",
        "\n",
        "    if args.train_set is \"ImageNet\":\n",
        "      trainset = torch.utils.data.DataLoader(ILSVRC2017Dataset(scale=args.scale, resize=args.resize), batch_size=args.batch_size)\n",
        "    elif args.train_set is \"BSDS\":\n",
        "      trainset = torch.utils.data.DataLoader(BSDS500Dataset(split=\"train\", scale=args.scale, resize=args.resize), batch_size=args.batch_size)\n",
        "\n",
        "    testset = torch.utils.data.DataLoader(BSDS500Dataset(split=\"val\", scale=args.scale, resize=args.resize), batch_size=1)\n",
        "\n",
        "    # Create the outputs folder if not created already\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    print(\"Beginning training ...\")\n",
        "    if args.gpu:\n",
        "        cnn.cuda()\n",
        "    start = time.time()\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    valid_PSNR = []\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Train the Model\n",
        "        cnn.train()  # Change model to 'train' mode\n",
        "        losses = []\n",
        "\n",
        "        for i_batch, sample_batched in enumerate(trainset):\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          input = sample_batched[\"y_low\"]\n",
        "          out = cnn(input)\n",
        "\n",
        "          loss = criterion(out, sample_batched[\"y_high\"])\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          losses.append(loss.data.item())\n",
        "\n",
        "        # plot training images\n",
        "        avg_loss = np.mean(losses)\n",
        "        train_losses.append(avg_loss)\n",
        "        time_elapsed = time.time() - start\n",
        "        print(\n",
        "            \"Epoch [%d/%d], Train Loss: %.4f, Time (s): %.2f\"\n",
        "            % (epoch + 1, args.epochs, avg_loss, time_elapsed)\n",
        "        )\n",
        "\n",
        "        # Evaluate the model\n",
        "        cnn.eval()  # Change model to 'eval' mode\n",
        "\n",
        "        val_loss, val_psnr = run_validation_step(cnn, criterion, testset)\n",
        "\n",
        "        time_elapsed = time.time() - start\n",
        "        valid_losses.append(val_loss)\n",
        "        valid_PSNR.append(val_psnr)\n",
        "\n",
        "        print(\n",
        "            \"Epoch [%d/%d], Val Loss: %.4f, Val PSNR: %.4f, Time(s): %.2f\"\n",
        "            % (epoch + 1, args.epochs, val_loss, val_psnr, time_elapsed)\n",
        "          )\n",
        "        \n",
        "        # Learning rate decay\n",
        "        curr_lr = optimizer.param_groups[0]['lr']\n",
        "        if epoch > 10 and curr_lr > 0.0001:\n",
        "          scheduler.step()\n",
        "\n",
        "        if curr_lr < 0.0001:\n",
        "          for g in optimizer.param_groups:\n",
        "            g['lr'] = 0.0001\n",
        "\n",
        "    # Plot training curve\n",
        "    plot1 = plt.figure(1)\n",
        "    plt.plot(train_losses, \"ro-\", label=\"Train\")\n",
        "    plt.plot(valid_losses, \"go-\", label=\"Validation\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.savefig(save_dir + \"/training_curve.png\")\n",
        "\n",
        "    plot2 = plt.figure(2)\n",
        "    plt.plot(valid_PSNR, \"yo-\", label=\"PSNR\")\n",
        "    plt.legend()\n",
        "    plt.title(\"PSNR\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.savefig(save_dir + \"/PSNR_curve.png\")\n",
        "\n",
        "    print(\"Final learning rate: %.4f\" %optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    if args.checkpoint:\n",
        "        print(\"Saving model...\")\n",
        "        torch.save(cnn.state_dict(), args.checkpoint)\n",
        "\n",
        "    return cnn, train_losses, valid_losses, valid_PSNR"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dPEllswFDm_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Oru2s9VqDm_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "    \"gpu\": True,\n",
        "    \"valid\": True,\n",
        "    \"checkpoint\": \"model.pkl\",\n",
        "    \"model\": \"ESPCN\",\n",
        "    \"scale\": 3,\n",
        "    \"resize\": 480,  # Images will be transformed to [resize, resize] square image\n",
        "    \"kernel\": 3,\n",
        "    \"learn_rate\": 0.001,\n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 50,\n",
        "    \"seed\": 42,\n",
        "    \"optimizor\": \"Adam\",\n",
        "    \"train_set\": \"ImageNet\"\n",
        "}\n",
        "args.update(args_dict)\n",
        "cnn, train_loss, val_loss, val_PSNR = train(args)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pny-9IhwDm_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "    \"gpu\": True,\n",
        "    \"valid\": False,\n",
        "    \"checkpoint\": \"model-unet.pkl\",\n",
        "    \"model\": \"UNet\",\n",
        "    \"scale\": 3,\n",
        "    \"resize\": 480,  # Images will be transformed to [resize, resize] square image\n",
        "    \"kernel\": 3,\n",
        "    \"learn_rate\": 0.001,\n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 100,\n",
        "    \"seed\": 42,\n",
        "    \"optimizor\": \"Adam\",\n",
        "    \"train_set\": \"ImageNet\"\n",
        "}\n",
        "args.update(args_dict)\n",
        "cnn = UNet(3, 8, 1, 1)\n",
        "cnn = train(args, cnn)"
      ],
      "metadata": {
        "id": "BXXCMyrWQMZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BRI8IDUmDm_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# val_set = BSDS500Dataset(split=\"val\", scale=3, resize=480)\n",
        "val_set = ILSVRC2017Dataset(scale=args.scale, resize=args.resize)\n",
        "\n",
        "index = 0\n",
        "cnn.eval()\n",
        "model_psnr = []\n",
        "bicubic_psnr = []\n",
        "for item in tqdm(val_set):\n",
        "\n",
        "  # Compute average PSNR on given val_set\n",
        "  img_arr = item[\"y_low\"]\n",
        "  out = cnn(img_arr.unsqueeze(0))\n",
        "  regular_upscale = Resize([args.resize, args.resize], InterpolationMode.BICUBIC)(img_arr)\n",
        "  bicubic_psnr.append(psnr(regular_upscale, item[\"y_high\"]))\n",
        "  model_psnr.append(psnr(out, item[\"y_high\"]))\n",
        "\n",
        "  # Visualization\n",
        "  if index == -1:\n",
        "    img_arr = item[\"y_low\"]\n",
        "    img = ToPILImage()(img_arr)\n",
        "    img.save(\"in.jpg\", \"JPEG\")\n",
        "\n",
        "    out = cnn(img_arr.unsqueeze(0))\n",
        "    out_img = ToPILImage()(out.squeeze(0))\n",
        "    out_img.save(\"out.jpg\", \"JPEG\")\n",
        "    \n",
        "  index += 1\n",
        "\n",
        "print(np.mean(model_psnr))\n",
        "print(np.mean(bicubic_psnr))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "s3F_G5alDm_T"
      }
    }
  ]
}