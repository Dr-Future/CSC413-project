{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMffTZDl8IuXYV4UYPRKL+l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import packages"],"metadata":{"id":"qgFvI6b8HdJz"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"1YfLyw9jHVIa","executionInfo":{"status":"ok","timestamp":1650058134690,"user_tz":240,"elapsed":8726,"user":{"displayName":"Future Hu","userId":"14398988949894597675"}}},"outputs":[],"source":["import os\n","import pickle\n","import sys\n","import tarfile\n","\n","from PIL import Image\n","from six.moves.urllib.request import urlretrieve\n","\n","import argparse\n","import math\n","import time\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import numpy.random as npr\n","import scipy.misc\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable"]},{"cell_type":"markdown","source":["The actual ESPCN model"],"metadata":{"id":"KNj2Rq4iIcan"}},{"cell_type":"code","source":["class ESPCN_model(nn.Module):\n","    def __init__(self, layer1_channel, layer2_channel, upscale_factor):\n","        super().__init__()\n","\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(1, layer1_channel, kernel_size=5, stride=1, padding=2),\n","            nn.Tanh()\n","        )\n","\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(layer1_channel, layer2_channel, kernel_size=3, stride=1, padding=1),\n","            nn.Tanh()\n","        )\n","\n","        self.layer3 = nn.Sequential(\n","            nn.ConvTranspose2d(layer2_channel, upscale_factor ** 2, kernel_size=3, stride=1, padding=1),\n","            nn.PixelShuffle(upscale_factor) # This function is literally build for ESPCN\n","        )\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        return out"],"metadata":{"id":"b5--A1VEIc2J","executionInfo":{"status":"ok","timestamp":1650061015328,"user_tz":240,"elapsed":187,"user":{"displayName":"Future Hu","userId":"14398988949894597675"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Code for training (adapted from PA2)\n","\n","NOTE: Some of the utilities functions are not updated \n","e.x. we are using BSDS500 rather than CIFAR"],"metadata":{"id":"zOJ1G8nmHgWp"}},{"cell_type":"code","source":["class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","        \n","def train(args, cnn=None):\n","    # Set the maximum number of threads to prevent crash in Teaching Labs\n","    # torch.set_num_threads(5)\n","\n","    # Numpy random seed\n","    npr.seed(args.seed)\n","\n","    # Save directory\n","    save_dir = \"outputs/\" + args.experiment_name\n","\n","    # INPUT CHANNEL\n","    num_in_channels = 1\n","\n","    # LOAD THE MODEL\n","    if cnn is None:\n","        cnn = ESPCN_model(64, 32, 3)\n","\n","    # LOSS FUNCTION\n","    criterion = nn.MSELoss()\n","    optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4, nesterov=False)\n","\n","    # DATA\n","    print(\"Loading data...\")\n","    (x_train, y_train), (x_test, y_test) = load_cifar10()\n","\n","    print(\"Transforming data...\")\n","    train_rgb, train_grey = process(x_train, y_train, downsize_input=args.downsize_input)\n","    train_rgb_cat = get_rgb_cat(train_rgb, colours)\n","    test_rgb, test_grey = process(x_test, y_test, downsize_input=args.downsize_input)\n","    test_rgb_cat = get_rgb_cat(test_rgb, colours)\n","\n","    # Create the outputs folder if not created already\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","\n","    print(\"Beginning training ...\")\n","    if args.gpu:\n","        cnn.cuda()\n","    start = time.time()\n","\n","    train_losses = []\n","    valid_losses = []\n","    valid_accs = []\n","    for epoch in range(args.epochs):\n","        # Train the Model\n","        cnn.train()  # Change model to 'train' mode\n","        losses = []\n","        for i, (xs, ys) in enumerate(get_batch(train_grey, train_rgb_cat, args.batch_size)):\n","            images, labels = get_torch_vars(xs, ys, args.gpu)\n","            # Forward + Backward + Optimize\n","            optimizer.zero_grad()\n","            outputs = cnn(images)\n","\n","            loss = compute_loss(\n","                criterion, outputs, labels, batch_size=args.batch_size, num_colours=num_colours\n","            )\n","            loss.backward()\n","            optimizer.step()\n","            losses.append(loss.data.item())\n","\n","        # plot training images\n","        if args.plot:\n","            _, predicted = torch.max(outputs.data, 1, keepdim=True)\n","            plot(\n","                xs,\n","                ys,\n","                predicted.cpu().numpy(),\n","                colours,\n","                save_dir + \"/train_%d.png\" % epoch,\n","                args.visualize,\n","                args.downsize_input,\n","            )\n","\n","        # plot training images\n","        avg_loss = np.mean(losses)\n","        train_losses.append(avg_loss)\n","        time_elapsed = time.time() - start\n","        print(\n","            \"Epoch [%d/%d], Loss: %.4f, Time (s): %d\"\n","            % (epoch + 1, args.epochs, avg_loss, time_elapsed)\n","        )\n","\n","        # Evaluate the model\n","        cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n","        val_loss, val_acc = run_validation_step(\n","            cnn,\n","            criterion,\n","            test_grey,\n","            test_rgb_cat,\n","            args.batch_size,\n","            colours,\n","            save_dir + \"/test_%d.png\" % epoch,\n","            args.visualize,\n","            args.downsize_input,\n","        )\n","\n","        time_elapsed = time.time() - start\n","        valid_losses.append(val_loss)\n","        valid_accs.append(val_acc)\n","        print(\n","            \"Epoch [%d/%d], Val Loss: %.4f, Val Acc: %.1f%%, Time(s): %.2f\"\n","            % (epoch + 1, args.epochs, val_loss, val_acc, time_elapsed)\n","        )\n","\n","    # Plot training curve\n","    plt.figure()\n","    plt.plot(train_losses, \"ro-\", label=\"Train\")\n","    plt.plot(valid_losses, \"go-\", label=\"Validation\")\n","    plt.legend()\n","    plt.title(\"Loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.savefig(save_dir + \"/training_curve.png\")\n","\n","    if args.checkpoint:\n","        print(\"Saving model...\")\n","        torch.save(cnn.state_dict(), args.checkpoint)\n","\n","    return cnn"],"metadata":{"cellView":"code","id":"3Ff3lUQzHhJQ","executionInfo":{"status":"ok","timestamp":1650061978676,"user_tz":240,"elapsed":323,"user":{"displayName":"Future Hu","userId":"14398988949894597675"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Train the model"],"metadata":{"id":"2A-HLZ-2Wv29"}},{"cell_type":"code","source":["args = AttrDict()\n","args_dict = {\n","    \"gpu\": True,\n","    \"valid\": False,\n","    \"checkpoint\": \"\",\n","    \"colours\": \"./data/colours/colour_kmeans24_cat7.npy\",\n","    \"model\": \"UNet\",\n","    \"kernel\": 3,\n","    \"num_filters\": 32,\n","    'learn_rate':0.001, \n","    \"batch_size\": 100,\n","    \"epochs\": 25,\n","    \"seed\": 42,\n","    \"plot\": True,\n","    \"experiment_name\": \"colourization_cnn\",\n","    \"visualize\": False,\n","    \"downsize_input\": False,\n","}\n","args.update(args_dict)\n","cnn = train(args)"],"metadata":{"id":"hKUcO-YqWxvW"},"execution_count":null,"outputs":[]}]}